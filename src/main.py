import os
import time
import pandas as pd
import crawler  # í¬ë¡¤ë§ ê¸°ëŠ¥ ëª¨ë“ˆ
import csv_to_db  # DB ì²˜ë¦¬ ê¸°ëŠ¥ ëª¨ë“ˆ
from datetime import date, timedelta  # ë‚ ì§œ ê³„ì‚°ì„ ìœ„í•´ import ì¶”ê°€


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜: ë°ì´í„° ìˆ˜ì§‘ë¶€í„° DB ì ì¬ê¹Œì§€ ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """
    # --- 1. ì„¤ì • ê°’ ---
    URL = "https://data.kma.go.kr/data/gaw/selectSpiRltmList.do?pgmNo=734"

    target_date = date.today() - timedelta(days=2)
    START_DATE = target_date.strftime("%Y%m%d")
    END_DATE = target_date.strftime("%Y%m%d")

    print(f"â–¶ ë™ì ìœ¼ë¡œ ì„¤ì •ëœ ë‚ ì§œ: {START_DATE}")

    REGIONS_TO_EXPAND = ["ê°•ì›íŠ¹ë³„ìì¹˜ë„", "ê²½ìƒë‚¨ë„", "ëŒ€ì „ê´‘ì—­ì‹œ", "ì¶©ì²­ë¶ë„"]
    LOCATIONS_TO_SELECT = ["ì¶˜ì²œ (101)", "í•©ì²œ (285)", "ëŒ€ì „ (133)", "ì¶©ì£¼ (127)"]
    SPI_ELEMENTS_TO_SELECT = ["SPI1", "SPI2", "SPI3", "SPI4", "SPI5", "SPI6", "SPI9", "SPI12", "SPI18", "SPI24"]

    # ì§€ì  IDì™€ DB í…Œì´ë¸” ì´ë¦„ ë§¤í•‘
    STATION_TABLE_MAP = {
        101: 'drought_impact_chuncheon_spi_index',
        127: 'drought_impact_chungju_spi_index',
        133: 'drought_impact_daejeon_spi_index',
        285: 'drought_impact_hapcheon_spi_index'
    }

    # ë‹¤ìš´ë¡œë“œ í´ë” ê²½ë¡œ ì„¤ì •
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(current_dir)
    DOWNLOAD_DIR = os.path.join(project_root, "output")

    # --- 2. í¬ë¡¤ë§ ë° ë‹¤ìš´ë¡œë“œ ì‹¤í–‰ ---
    driver = None
    try:
        driver, wait = crawler.setup_driver(DOWNLOAD_DIR)
        driver.get(URL)
        crawler.set_dates(driver, wait, START_DATE, END_DATE)
        crawler.select_locations(driver, wait, REGIONS_TO_EXPAND, LOCATIONS_TO_SELECT)
        crawler.select_elements(driver, wait, SPI_ELEMENTS_TO_SELECT)
        crawler.search_and_download(driver, wait)

        print("\nâ–¶ íŒŒì¼ ë‹¤ìš´ë¡œë“œë¥¼ 20ì´ˆ ë™ì•ˆ ê¸°ë‹¤ë¦½ë‹ˆë‹¤...")
        time.sleep(20)
        print("ğŸ‰ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
    except Exception as e:
        print(f"\ní¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    finally:
        if driver:
            driver.quit()
            print("\nâ–¶ ë¸Œë¼ìš°ì €ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")

    # --- 3. ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ DBì— ì ì¬ ---
    print("\n========================================")
    print("â–¶ ë°ì´í„°ë² ì´ìŠ¤ ì ì¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("========================================")

    latest_csv = csv_to_db.find_latest_csv_file(DOWNLOAD_DIR)

    if latest_csv:
        try:
            raw_df = pd.read_csv(latest_csv, encoding='cp949')
            transformed_df = csv_to_db.transform_dataframe(raw_df)

            for station_id, table_name in STATION_TABLE_MAP.items():
                station_df = transformed_df[transformed_df['station_id'] == station_id].copy()
                if not station_df.empty:
                    csv_to_db.insert_data_to_db(station_df, table_name)
                else:
                    print(f"\n- ì •ë³´: station_id {station_id}ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ CSV íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")

            print("\nğŸ‰ ëª¨ë“  DB ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        except Exception as e:
            print(f"\n!! DB ì ì¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


if __name__ == "__main__":
    main()